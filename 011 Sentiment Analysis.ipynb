{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "de5f22618689967f01319fb4cd070269718539d4a91f849d771b5bf4ab8f102b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\nvs\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\nvs\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import string\n",
    "import heapq\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('grayscale')\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams['figure.dpi'] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(tokens):\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(token) for token in tokens]\n",
    "    \n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(data, sentiment):\n",
    "    train_data_labeled = data[sentiment_df.label == sentiment]\n",
    "    train_data_remaining = data[sentiment_df.label != sentiment].sample(len(train_data_labeled))\n",
    "    train_data = pd.concat([train_data_labeled, train_data_remaining], ignore_index=True)\n",
    "\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_comment(comment):\n",
    "    filtered_comment = comment.replace('\\n','') # remove enters\n",
    "    filtered_comment = filtered_comment.lower() # decapitalize\n",
    "    filtered_comment = \"\".join([char for char in filtered_comment if char not in string.punctuation]) # remove punctuation\n",
    "    filtered_comment = \"\".join([char for char in filtered_comment if char in \"abcdefghijklmnopqrstuvwxyz \"]) # remove strange chars\n",
    "    \n",
    "    return filtered_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(filtered_comment):\n",
    "    tokens = nltk.word_tokenize(filtered_comment) # Tokenize\n",
    "    tokens = [token for token in tokens if token not in stop_words] # filter stop words\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob('sentiment data/data/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  8.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter all comments\n",
    "filtered_data_dict = {}\n",
    "for f in tqdm(all_files):\n",
    "    comments = open(f, 'r', encoding='utf-8').readlines()\n",
    "\n",
    "    filtered_data = []\n",
    "    for comment in comments:\n",
    "        if 'ago' in comment or 'award' in comment or 'carregar mais' in comment or 'permalinkembed' in comment or 'http' in comment:\n",
    "            continue\n",
    "\n",
    "        tokens = tokenize(comment)\n",
    "        stemmed = tokenize(comment)\n",
    "\n",
    "        if len(tokens) > 0:\n",
    "            if f in filtered_data_dict.keys():\n",
    "                filtered_data_dict[f].append(stemmed)\n",
    "            else:\n",
    "                filtered_data_dict[f] = [stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1163.44it/s]\n"
     ]
    }
   ],
   "source": [
    "wordfreq = {}\n",
    "for key in tqdm(filtered_data_dict.keys()):\n",
    "    for sentence in filtered_data_dict[key]:\n",
    "        for token in sentence:\n",
    "            if token not in wordfreq.keys():\n",
    "                wordfreq[token] = 1\n",
    "            else:\n",
    "                wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "13918"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "len(wordfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:04<00:00, 10.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Filter all comments\n",
    "filtered_data_dict = {}\n",
    "for f in tqdm(all_files):\n",
    "    comments = open(f, 'r', encoding='utf-8').readlines()\n",
    "\n",
    "    filtered_data = []\n",
    "    for comment in comments:\n",
    "        if 'ago' in comment or 'award' in comment or 'carregar mais' in comment or 'permalinkembed' in comment or 'http' in comment:\n",
    "            continue\n",
    "\n",
    "        filtered_comment = filter_comment(comment)\n",
    "        tokens = tokenize(filtered_comment)\n",
    "        stemmed = stemmer(tokens)\n",
    "\n",
    "        if len(tokens) > 0:\n",
    "            if f in filtered_data_dict.keys():\n",
    "                filtered_data_dict[f].append(stemmed)\n",
    "            else:\n",
    "                filtered_data_dict[f] = [stemmed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 1786.74it/s]\n"
     ]
    }
   ],
   "source": [
    "wordfreq = {}\n",
    "for key in tqdm(filtered_data_dict.keys()):\n",
    "    for sentence in filtered_data_dict[key]:\n",
    "        for token in sentence:\n",
    "            if token not in wordfreq.keys():\n",
    "                wordfreq[token] = 1\n",
    "            else:\n",
    "                wordfreq[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8117"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(wordfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 8117/8117 [00:00<00:00, 1351856.96it/s]\n"
     ]
    }
   ],
   "source": [
    "most_freq = {}\n",
    "for word in tqdm(wordfreq.keys()):\n",
    "    if wordfreq[word] > 20:\n",
    "        most_freq[word] = wordfreq[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(most_freq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:06<00:00,  8.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for f in tqdm(filtered_data_dict.keys()):\n",
    "    sentence_vectors = []\n",
    "    for sentence in filtered_data_dict[f]:\n",
    "        sent_vec = []\n",
    "        for token in most_freq.keys():\n",
    "            if token in sentence:\n",
    "                sent_vec.append(1)\n",
    "            else:\n",
    "                sent_vec.append(0)\n",
    "        sentence_vectors.append(sent_vec)\n",
    "    filtered_data_dict[f] = pd.DataFrame(sentence_vectors, columns = list(most_freq.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing sentiment data\n",
    "sent_df = pd.read_csv('sentiment data/crowdflower-sentiment-analysis-in-text/data/text_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 40000/40000 [00:32<00:00, 1239.46it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generating sentiment labels\n",
    "sentence_vectors_sentiment = []\n",
    "for i, row in tqdm(sent_df.iterrows(), total = len(sent_df)):\n",
    "    filtered_comment = filter_comment(row.content)\n",
    "    tokens = tokenize(filtered_comment)\n",
    "    stemmed = stemmer(tokens)\n",
    "\n",
    "    sent_vec = []\n",
    "    for token in most_freq.keys():\n",
    "        if token in stemmed:\n",
    "            sent_vec.append(1)\n",
    "        else:\n",
    "            sent_vec.append(0)\n",
    "    sentence_vectors_sentiment.append(sent_vec + [row.sentiment])\n",
    "\n",
    "sentiment_df = pd.DataFrame(sentence_vectors_sentiment, columns = list(most_freq.keys()) + ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True     708\n",
       "False     76\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "# How many words never appear\n",
    "(sentiment_df != 0).any(axis=0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove words that never appear\n",
    "features = []\n",
    "for word, appears in (sentiment_df != 0).any(axis=0).iteritems():\n",
    "    if appears and word != 'label':\n",
    "        features.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = sent_df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['empty',\n",
       " 'sadness',\n",
       " 'enthusiasm',\n",
       " 'neutral',\n",
       " 'worry',\n",
       " 'surprise',\n",
       " 'love',\n",
       " 'fun',\n",
       " 'hate',\n",
       " 'happiness',\n",
       " 'boredom',\n",
       " 'relief',\n",
       " 'anger']"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "list(sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 13/13 [18:43<00:00, 86.44s/it]\n"
     ]
    }
   ],
   "source": [
    "classifiers = {}\n",
    "for sentiment in tqdm(sentiments):\n",
    "    classifiers[sentiment] = MLPClassifier(hidden_layer_sizes = [400, 300])\n",
    "    train_data = get_train_data(sentiment_df[features + ['label']], sentiment)\n",
    "    classifiers[sentiment].fit(train_data.drop('label', axis = 1), train_data.label == sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 50/50 [00:19<00:00,  2.52it/s]\n"
     ]
    }
   ],
   "source": [
    "sentiment_results = []\n",
    "for f in tqdm(filtered_data_dict.keys()):\n",
    "    if len(filtered_data_dict[f]) > 0:\n",
    "        player_results = [f.replace('sentiment data/data\\\\','').replace('.txt','').replace('_',' to ')]\n",
    "        for sentiment in sentiments:\n",
    "            pred = classifiers[sentiment].predict(filtered_data_dict[f][features])\n",
    "            pred_prob = classifiers[sentiment].predict_proba(filtered_data_dict[f][features])[:,1]\n",
    "            player_results.append(pred.mean())\n",
    "        sentiment_results.append(player_results)\n",
    "\n",
    "columns = ['player']\n",
    "for sentiment in sentiments:\n",
    "    columns.append(sentiment)\n",
    "\n",
    "sentiment_results_df = pd.DataFrame(sentiment_results, columns = columns)"
   ]
  },
  {
   "source": [
    "for i, row in sentiment_results_df.iterrows():\n",
    "    for i, sentiment in enumerate(sentiments):\n",
    "        plt.bar(i, row[sentiment], width = 0.2, color = 'C0')\n",
    "\n",
    "    plt.title(row.player.replace('sentiment data/data\\\\','').replace('.txt','').replace('_',' to '))\n",
    "    plt.xticks(range(len(sentiments)), sentiments, rotation=45)\n",
    "\n",
    "    plt.savefig(row.player.replace('sentiment data/data','sentiment data/output').replace('txt','png'))"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                  player     empty   sadness  enthusiasm  \\\n",
       "0      Alexandre Lacazette to Arsenal FC  0.594595  0.301802    0.436937   \n",
       "1       Alvaro Morata to Atletico Madrid  0.541667  0.337963    0.537037   \n",
       "2            Alvaro Morata to Chelsea FC  0.463203  0.350649    0.523810   \n",
       "3    Angel Di Maria to Manchester United  0.500000  0.466667    0.514286   \n",
       "4  Angel Di Maria to Paris Saint-Germain  0.517241  0.467980    0.502463   \n",
       "\n",
       "    neutral     worry  surprise      love       fun      hate  happiness  \\\n",
       "0  0.630631  0.378378  0.396396  0.319820  0.409910  0.599099   0.306306   \n",
       "1  0.425926  0.467593  0.449074  0.361111  0.513889  0.592593   0.356481   \n",
       "2  0.567100  0.432900  0.515152  0.385281  0.502165  0.480519   0.350649   \n",
       "3  0.509524  0.438095  0.476190  0.295238  0.500000  0.561905   0.342857   \n",
       "4  0.448276  0.497537  0.492611  0.300493  0.482759  0.620690   0.310345   \n",
       "\n",
       "    boredom    relief     anger  \n",
       "0  0.445946  0.337838  0.626126  \n",
       "1  0.412037  0.402778  0.583333  \n",
       "2  0.489177  0.467532  0.458874  \n",
       "3  0.371429  0.400000  0.585714  \n",
       "4  0.512315  0.482759  0.625616  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>player</th>\n      <th>empty</th>\n      <th>sadness</th>\n      <th>enthusiasm</th>\n      <th>neutral</th>\n      <th>worry</th>\n      <th>surprise</th>\n      <th>love</th>\n      <th>fun</th>\n      <th>hate</th>\n      <th>happiness</th>\n      <th>boredom</th>\n      <th>relief</th>\n      <th>anger</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Alexandre Lacazette to Arsenal FC</td>\n      <td>0.594595</td>\n      <td>0.301802</td>\n      <td>0.436937</td>\n      <td>0.630631</td>\n      <td>0.378378</td>\n      <td>0.396396</td>\n      <td>0.319820</td>\n      <td>0.409910</td>\n      <td>0.599099</td>\n      <td>0.306306</td>\n      <td>0.445946</td>\n      <td>0.337838</td>\n      <td>0.626126</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Alvaro Morata to Atletico Madrid</td>\n      <td>0.541667</td>\n      <td>0.337963</td>\n      <td>0.537037</td>\n      <td>0.425926</td>\n      <td>0.467593</td>\n      <td>0.449074</td>\n      <td>0.361111</td>\n      <td>0.513889</td>\n      <td>0.592593</td>\n      <td>0.356481</td>\n      <td>0.412037</td>\n      <td>0.402778</td>\n      <td>0.583333</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Alvaro Morata to Chelsea FC</td>\n      <td>0.463203</td>\n      <td>0.350649</td>\n      <td>0.523810</td>\n      <td>0.567100</td>\n      <td>0.432900</td>\n      <td>0.515152</td>\n      <td>0.385281</td>\n      <td>0.502165</td>\n      <td>0.480519</td>\n      <td>0.350649</td>\n      <td>0.489177</td>\n      <td>0.467532</td>\n      <td>0.458874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Angel Di Maria to Manchester United</td>\n      <td>0.500000</td>\n      <td>0.466667</td>\n      <td>0.514286</td>\n      <td>0.509524</td>\n      <td>0.438095</td>\n      <td>0.476190</td>\n      <td>0.295238</td>\n      <td>0.500000</td>\n      <td>0.561905</td>\n      <td>0.342857</td>\n      <td>0.371429</td>\n      <td>0.400000</td>\n      <td>0.585714</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Angel Di Maria to Paris Saint-Germain</td>\n      <td>0.517241</td>\n      <td>0.467980</td>\n      <td>0.502463</td>\n      <td>0.448276</td>\n      <td>0.497537</td>\n      <td>0.492611</td>\n      <td>0.300493</td>\n      <td>0.482759</td>\n      <td>0.620690</td>\n      <td>0.310345</td>\n      <td>0.512315</td>\n      <td>0.482759</td>\n      <td>0.625616</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sentiment_results_df.to_csv('sentiment data/sentiment_results.csv')\n",
    "sentiment_results_df.head()"
   ]
  }
 ]
}